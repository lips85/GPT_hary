{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.chat_models.ollama import ChatOllama\n",
    "from langchain_core.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "llm_openai = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    streaming=True,\n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler(),\n",
    "    ],\n",
    ")\n",
    "\n",
    "llm = ChatOllama(\n",
    "    temperature=0.1,\n",
    "    model=\"openhermes:latest\",\n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler(),\n",
    "    ],\n",
    ")\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "prompt_write_Haikus = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"당신은 Haiku의 전문가 입니다. Haiku는 5-7-5의 형식을 가지는 일본 시입니다. 당신은 한국인 입니다. 한국어를 사용합니다.\",\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"프로그래밍 언어 {topic}에 대한 재미있는 Haiku를 하나만 작성해줘. 2개 작성하지 마. 작성한 이후에는 한줄을 띄워줘.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "prompt_expliain_Haikus = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"당신은 Haiku의 전문가 입니다. 당신은 Haiku에 대해 자세하게 설명하는것을 좋아합니다. Haiku는 5-7-5의 형식을 가지는 일본 시입니다. 당신은 한국인 입니다. 한국어를 사용합니다.\",\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"{output}에 대한 전문가적인 해석을 해줘. 시에 대해 다시 읽지 말고, 시를 해석할때는 아주 자세하게 설명해줘.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "chain_write = prompt_write_Haikus | llm_openai | output_parser\n",
    "\n",
    "chain_explain = prompt_expliain_Haikus | llm_openai | output_parser\n",
    "\n",
    "\n",
    "final_chain = {\"output\": chain_write} | chain_explain\n",
    "\n",
    "final_chain.invoke({\"topic\": input()})"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
