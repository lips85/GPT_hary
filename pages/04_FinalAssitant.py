# (EN)
# Refactor the agent you made in the previous assignment into an OpenAI Assistant.
# Give it a user interface with Streamlit that displays the conversation history.
# Allow the user to use its own OpenAI API Key, load it from an st.input inside of st.sidebar
# Using st.sidebar put a link to the Github repo with the code of your Streamlit app.

# (KR)
# ì´ì „ ê³¼ì œì—ì„œ ë§Œë“  ì—ì´ì „íŠ¸ë¥¼ OpenAI ì–´ì‹œìŠ¤í„´íŠ¸ë¡œ ë¦¬íŒ©í„°ë§í•©ë‹ˆë‹¤.
# ëŒ€í™” ê¸°ë¡ì„ í‘œì‹œí•˜ëŠ” Streamlit ì„ ì‚¬ìš©í•˜ì—¬ ìœ ì € ì¸í„°í˜ì´ìŠ¤ë¥¼ ì œê³µí•˜ì„¸ìš”.
# ìœ ì €ê°€ ìì²´ OpenAI API í‚¤ë¥¼ ì‚¬ìš©í•˜ë„ë¡ í—ˆìš©í•˜ê³ , st.sidebar ë‚´ë¶€ì˜ st.inputì—ì„œ ì´ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
# st.sidebarë¥¼ ì‚¬ìš©í•˜ì—¬ Streamlit app ì˜ ì½”ë“œê³¼ í•¨ê»˜ ê¹ƒí—ˆë¸Œ ë¦¬í¬ì§€í† ë¦¬ì— ë§í¬ë¥¼ ë„£ìŠµë‹ˆë‹¤.

import time
import json
import streamlit as st
from langchain.utilities.duckduckgo_search import DuckDuckGoSearchAPIWrapper
from langchain.utilities.wikipedia import WikipediaAPIWrapper
from langchain.document_loaders.web_base import WebBaseLoader
from openai import OpenAI
from utils.functions.chat import ChatMemory
from dotenv import load_dotenv
from utils.constant.constant import OPENAI_MODEL
from utils.functions.save_env import SaveEnv
from utils.functions.debug import Debug

load_dotenv()


# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
for key, default in [
    ("messages", []),
    ("api_key", None),
    ("api_key_check", False),
    ("openai_model", "ì„ íƒí•´ì£¼ì„¸ìš”"),
    ("openai_model_check", False),
    ("assistant_id", ""),
    ("assistant", ""),
]:
    if key not in st.session_state:
        st.session_state[key] = default


st.set_page_config(
    page_title="AssistantGPT",
    page_icon="ğŸš€",
    layout="wide",
)

st.markdown(
    """
    # ğŸš€ ë¦¬ì„œì¹˜ ë§ˆìŠ¤í„°  ğŸš€ 
    
    ê²€ìƒ‰ì€ ì €ì—ê²Œ ë§¡ê²¨ì£¼ì„¸ìš”! ì—¬ëŸ¬ë¶„ë“¤ì˜ ì‹œê°„ì„ ì•„ê»´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.
    (OpenAI Assistant APi ì‚¬ìš©)
 """
)


class ThreadClient:
    def __init__(self, client):
        self.client = client

    def get_run(self, run_id, thread_id):
        return self.client.beta.threads.runs.retrieve(
            run_id=run_id,
            thread_id=thread_id,
        )

    def send_message(self, thread_id, content):
        return self.client.beta.threads.messages.create(
            thread_id=thread_id, role="user", content=content
        )

    def get_messages(self, thread_id):
        messages = self.client.beta.threads.messages.list(thread_id=thread_id)
        messages = list(messages)
        messages.reverse()
        for message in messages:
            if message.role == "user":
                discussion_client.send_message(message.content[0].text.value, "user")

    def get_tool_outputs(self, run_id, thread_id):
        run = self.get_run(run_id, thread_id)
        outputs = []
        for action in run.required_action.submit_tool_outputs.tool_calls:
            action_id = action.id
            function = action.function
            outputs.append(
                {
                    "output": functions_map[function.name](
                        json.loads(function.arguments)
                    ),
                    "tool_call_id": action_id,
                }
            )
        return outputs

    def submit_tool_outputs(self, run_id, thread_id):
        outputs = self.get_tool_outputs(run_id, thread_id)
        discussion_client.send_message("ì´ìŠˆë¥¼ ì°¾ì•˜ì–´ìš”!", "ai")
        discussion_client.send_message(outputs[0]["output"], "ai")

        return self.client.beta.threads.runs.submit_tool_outputs(
            run_id=run_id,
            thread_id=thread_id,
            tool_outputs=outputs,
        )

    def wait_on_run(self, run, thread):
        while run.status == "queued" or run.status == "in_progress":
            run = self.get_run(run.id, thread.id)
            time.sleep(0.5)
        return run


class IssueSearchClient:

    def __init__(self):
        self.ddg = DuckDuckGoSearchAPIWrapper()
        self.w = WikipediaAPIWrapper()
        self.loader = WebBaseLoader()

    def get_websites_by_wikipedia_search(self, inputs):
        self.w = WikipediaAPIWrapper()
        query = inputs["query"]
        return self.w.run(query)

    def get_websites_by_duckduckgo_search(self, inputs):
        self.ddg = DuckDuckGoSearchAPIWrapper()
        query = inputs["query"]
        return self.ddg.run(query)

    def get_document_text(self, inputs):
        url = inputs["url"]
        self.loader = WebBaseLoader([url])
        self.docs = self.loader.load()
        return self.docs[0].page_content


issue_search_client = IssueSearchClient()
discussion_client = ChatMemory()

functions_map = {
    "get_websites_by_wikipedia_search": issue_search_client.get_websites_by_wikipedia_search,
    "get_websites_by_duckduckgo_search": issue_search_client.get_websites_by_duckduckgo_search,
    "get_document_text": issue_search_client.get_document_text,
}

functions = [
    {
        "type": "function",
        "function": {
            "name": "get_websites_by_wikipedia_search",
            "description": "Use this tool to find the websites for the given query.",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "The query you will search for. Example query: Research about the XZ backdoor",
                    }
                },
                "required": ["query"],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "get_websites_by_duckduckgo_search",
            "description": "Use this tool to find the websites for the given query.",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "The query you will search for. Example query: Research about the XZ backdoor",
                    }
                },
                "required": ["query"],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "get_document_text",
            "description": "Use this tool to load the website for the given url.",
            "parameters": {
                "type": "object",
                "properties": {
                    "url": {
                        "type": "string",
                        "description": "The url you will load. Example url: https://en.wikipedia.org/wiki/Backdoor_(computing)",
                    }
                },
                "required": ["url"],
            },
        },
    },
]

with st.sidebar:
    # API Key ì…ë ¥ í•„ë“œ
    st.text_input(
        "API_KEY ì…ë ¥",
        placeholder="sk-...",
        on_change=SaveEnv.save_api_key,  # ì¸ìŠ¤í„´ìŠ¤ ë©”ì„œë“œë¡œ ë³€ê²½
        key="api_key",
        type="password",
    )

    if st.session_state["api_key_check"]:
        st.success("ğŸ˜„ API_KEYê°€ ìœ íš¨í•©ë‹ˆë‹¤.")
    else:
        st.warning("API_KEYë¥¼ ì…ë ¥í•˜ì„¸ìš”.")

    st.button("ë””ë²„ê¹…ìš© ë²„íŠ¼", on_click=Debug.my_api_key)

    # OpenAI ëª¨ë¸ ì„ íƒ ë°•ìŠ¤
    st.selectbox(
        "OpenAI Modelì„ ì„ íƒí•˜ì„¸ìš”.",
        options=OPENAI_MODEL,
        on_change=SaveEnv.save_openai_model,  # ì¸ìŠ¤í„´ìŠ¤ ë©”ì„œë“œë¡œ ë³€ê²½
        key="openai_model",
    )

    if st.session_state["openai_model_check"]:
        st.success("ğŸ˜„ ëª¨ë¸ì´ ì„ íƒë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        st.warning("ëª¨ë¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")

    st.write(
        """
        Made by hary.
        
        Github
        https://github.com/lips85/GPT_hary

        streamlit
        https://hary-gpt.streamlit.app/
        """
    )

if not (st.session_state["api_key_check"] and st.session_state["openai_model_check"]):

    if not st.session_state["api_key_check"]:
        st.warning("Please provide an **:blue[OpenAI API Key]** on the sidebar.")

    if not st.session_state["openai_model_check"]:
        st.warning("Please write down a **:blue[OpenAI Model Select]** on the sidebar.")

else:
    client = OpenAI(api_key=st.session_state["api_key"])
    assistant = client.beta.assistants.create(
        name="Research Assistant",
        instructions="You help users do research on keyword from wikipedia and duckduckgo.",
        model="gpt-4o-mini-2024-07-18",
        tools=functions,
    )
    assistant_id = assistant.id
    st.session_state["assistant_id"] = assistant_id

    discussion_client.send_message("ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”!", "ai", save=False)
    discussion_client.paint_history()
    query = st.chat_input("Ask a question to the website.")

    if query:
        st.session_state["query"] = query
        discussion_client.send_message(query, "human")
        thread = client.beta.threads.create(
            messages=[
                {
                    "role": "user",
                    "content": f"{query}",
                }
            ]
        )
        thread_id = thread.id
        run = client.beta.threads.runs.create(
            thread_id=thread_id,
            assistant_id=assistant_id,
        )
        run_id = run.id

        assistant = ThreadClient(client)
        run = assistant.wait_on_run(run, thread)

        if run:
            discussion_client.send_message("ì´ìŠˆë¥¼ ì°¾ê³  ìˆì–´ìš”!", "ai", save=False)
            discussion_client.paint_history()
            assistant.get_tool_outputs(run_id, thread_id)
            assistant.submit_tool_outputs(run_id, thread_id)
            st.download_button(
                label="ì±„íŒ… ë‚´ì—­ ë‹¤ìš´ë¡œë“œ",
                data=json.dumps(st.session_state["messages"]),
                file_name="chat_history.txt",
                mime="text/plain",
            )

    else:
        st.session_state["messages"] = []
