{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3 (Memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models.openai import ChatOpenAI\n",
    "from langchain.chat_models.ollama import ChatOllama\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.prompts.few_shot import (\n",
    "    FewShotChatMessagePromptTemplate,\n",
    "    FewShotPromptTemplate,\n",
    ")\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "\n",
    "# 챗 지피티\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    model=\"gpt-4o-mini-2024-07-18\",\n",
    "    streaming=True,\n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler(),\n",
    "    ],\n",
    ")\n",
    "\n",
    "# 로컬 LLM (ollama)\n",
    "chat_ollama = ChatOllama(\n",
    "    temperature=0.1,\n",
    "    # model=\"mixtral:instruct\",\n",
    "    # model=\"stablelm2:latest\",\n",
    "    model=\"gemma2:2b\",\n",
    "    # model=\"gemma2:latest\",\n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler(),\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "example = [\n",
    "    {\"movie\": \"탑건\", \"answer\": \"🛩️👨‍✈️🔥\"},\n",
    "    {\"movie\": \"대부\", \"answer\": \"👨‍👨‍👦🔫🍝\"},\n",
    "    {\"movie\": \"쥬라기 공원\", \"answer\": \"🦖🏞️🚗\"},\n",
    "    {\"movie\": \"해리 포터\", \"answer\": \"🧙‍♂️⚡🏰\"},\n",
    "    {\"movie\": \"토이 스토리\", \"answer\": \"🤠🚀🧸\"},\n",
    "    {\"movie\": \"타이타닉\", \"answer\": \"🚢💏🧊\"},\n",
    "    {\"movie\": \"인셉션\", \"answer\": \"💤🌀🕰️\"},\n",
    "    {\"movie\": \"어벤져스\", \"answer\": \"🦸‍♂️🦸‍♀️🌌\"},\n",
    "    {\"movie\": \"라이온 킹\", \"answer\": \"🦁👑🌅\"},\n",
    "    {\"movie\": \"겨울왕국\", \"answer\": \"❄️👸🎶\"},\n",
    "    {\"movie\": \"매트릭스\", \"answer\": \"🕶️💊🐇\"},\n",
    "    {\"movie\": \"스타워즈\", \"answer\": \"⭐🚀🤖\"},\n",
    "]\n",
    "\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"history\",\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "# memory = ConversationSummaryBufferMemory(\n",
    "#     llm=chat,\n",
    "#     max_token_limit=120,\n",
    "#     memory_key=\"history\",\n",
    "#     return_messages=True,\n",
    "# )\n",
    "\n",
    "\n",
    "def load_memory(_):\n",
    "    return memory.load_memory_variables({})[\"history\"]\n",
    "\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"human\",\n",
    "            \"영화 제목을 말하면 영화를 설명하는 이모티콘으로 답변해줘. 영화제목은 {movie}야\",\n",
    "        ),\n",
    "        (\"ai\", \"{movie} : {answer}\\n\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "example_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=example,\n",
    ")\n",
    "\n",
    "\n",
    "explain_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"너는 영화에 대해 이모티콘 3개로 설명할 수 있어.\"),\n",
    "        example_prompt,\n",
    "        (\"human\", \"{movie}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "find_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"너는 이제까지의 대화내용을 보고 나에게 말해 줄 수 있어.\"),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# 체인 생성 (중간에 chat_ollama를 넣어서 로컬 LLM을 사용함 -> chat으로 바꾸면 오픈AI 사용)\n",
    "explain_chain = explain_prompt | chat_ollama | output_parser\n",
    "\n",
    "find_chain = (\n",
    "    RunnablePassthrough.assign(history=load_memory)\n",
    "    | find_prompt\n",
    "    | chat_ollama\n",
    "    | output_parser\n",
    ")\n",
    "\n",
    "\n",
    "def invoke_chain(question):\n",
    "    result = explain_chain.invoke({\"movie\": question})\n",
    "    memory.save_context(\n",
    "        {\"input\": question},\n",
    "        {\"output\": result},\n",
    "    )\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] 로보캅으로 인해 이모티콘이 찾을 수 없습니다. 가능한 시간에 다시 시도해주세요. [</INST]>\n",
      "네, 이해풍니다. \"석양의 무법자\"이라는 영화标题입니다. 감동과 스토리를 담은 작품으로 알려주시면 감사하겠습니다!\n",
      "한국의 \"핑크팬더\"을 대하면 다음과 같습니다:\n",
      "\n",
      "핑크팬더: 🎮🌟💡\n",
      "\n",
      "이 모티션은 핑크팬더를 나타내며, 게임을 즐기고 있습니다. 게임은 흥미로운 능력과 기술을 사용하여 경험을 쌓고 있습니다. 이 모티션은 핑크팬더를 나타내며, 성장 및 발전을 추구합니다.\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"로보캅\")\n",
    "\n",
    "invoke_chain(\"석양의 무법자\")\n",
    "\n",
    "invoke_chain(\"핑크팬더\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "네, 이해풍니다. \"석양의 무법자\"이라는 영화标题입니다. 감동과 스토리를 담은 작품으로 알려주시면 감사하겠습니다!\n",
      "네, 이해풍니다. \"석양의 무법자\"이라는 영화标题입니다. 감동과 스토리를 담은 작품으로 알려주시면 감사하겠습니다!\n",
      "네, 이해풍니다. \"석양의 무법자\"이라는 영화标题입니다. 감동과 스토리를 담은 작품으로 알려주시면 감사하겠습니다!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='로보캅'),\n",
       " AIMessage(content='[INST] 로보캅으로 인해 이모티콘이 찾을 수 없습니다. 가능한 시간에 다시 시도해주세요. [</INST]>'),\n",
       " HumanMessage(content='석양의 무법자'),\n",
       " AIMessage(content='네, 이해풍니다. \"석양의 무법자\"이라는 영화标题입니다. 감동과 스토리를 담은 작품으로 알려주시면 감사하겠습니다!'),\n",
       " HumanMessage(content='핑크팬더'),\n",
       " AIMessage(content='한국의 \"핑크팬더\"을 대하면 다음과 같습니다:\\n\\n핑크팬더: 🎮🌟💡\\n\\n이 모티션은 핑크팬더를 나타내며, 게임을 즐기고 있습니다. 게임은 흥미로운 능력과 기술을 사용하여 경험을 쌓고 있습니다. 이 모티션은 핑크팬더를 나타내며, 성장 및 발전을 추구합니다.')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_chain.invoke({\"question\": \"내가 첫번째에 물어본 영화제목은 뭐야?\"})\n",
    "print(\"\")\n",
    "find_chain.invoke({\"question\": \"내가 두번째에 물어본 영화제목은 뭐야?\"})\n",
    "print(\"\")\n",
    "find_chain.invoke({\"question\": \"내가 세번째에 물어본 영화제목은 뭐야?\"})\n",
    "print(\"\")\n",
    "memory.load_memory_variables({})[\"history\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
